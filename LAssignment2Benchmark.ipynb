{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Mining: Assignment 2\n",
    "\n",
    "Please complete all assignments in this notebook. You should submit this notebook, as well as a PDF version (See File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *\n",
    "plt.rcParams['savefig.dpi'] = 100 # This controls the size of your figures\n",
    "# Comment out and restart notebook if you only want the last output of each cell.\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a temporary read-only OpenML key. Replace with your own key later.\n",
    "oml.config.apikey = '11e82c8d91c5abece86f424369c71590'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A benchmark study (3 points (2+1))\n",
    "\n",
    "A benchmark study is an experiment in which multiple algorithms are evaluated on multiple datasets. The end goal is to study whether one algorithm is generally better than the others. Meaningful benchmark studies can grow quite complex, here we do a simplified variant.\n",
    "\n",
    "* Download OpenML datasets 37, 470, 1120, 1464 and 1471. They are sufficiently large (e.g., at least 500 data points) so that the performance estimation is trustworthy. Select at least three classifiers that we discussed in class, e.g. kNN, Logistic Regression, Random Forests, Gradient Boosting, SVMs, Naive Bayes. Note that some of these algorithms take longer to train. Evaluate all classifiers (with default parameter settings) on all datasets, using a 10-fold CV and AUC. Show the results in a table and interpret them. Which is the best algorithm in this benchmark?\n",
    "    * Note that these datasets have categorical features, different scales, missing values, and (likely) irrelevant features. You'll need to build pipelines to correctly build all models. Also remove any row identifiers (see, e.g., https://www.openml.org/d/1120)\n",
    "    * Hint: You can either compare the performances directly, or (better) use a statistical significance test, e.g. a pairwise t-test or (better) Wilcoxon signed ranks test, to see whether the performance differences are significant. This is covered in statistics courses. You can then count wins, ties and losses.\n",
    "* Repeat the benchmark, but now additionally optimize the main hyperparameters of each algorithm in a grid or random search (explore at least 5 values per hyperparameter, where possible). Does this affect the ranking of the algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>insu</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.00</td>\n",
       "      <td>768.00</td>\n",
       "      <td>768.00</td>\n",
       "      <td>768.00</td>\n",
       "      <td>768.00</td>\n",
       "      <td>768.00</td>\n",
       "      <td>768.00</td>\n",
       "      <td>768.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.85</td>\n",
       "      <td>120.89</td>\n",
       "      <td>69.11</td>\n",
       "      <td>20.54</td>\n",
       "      <td>79.80</td>\n",
       "      <td>31.99</td>\n",
       "      <td>0.47</td>\n",
       "      <td>33.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.37</td>\n",
       "      <td>31.97</td>\n",
       "      <td>19.36</td>\n",
       "      <td>15.95</td>\n",
       "      <td>115.24</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0.33</td>\n",
       "      <td>11.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.30</td>\n",
       "      <td>0.24</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.00</td>\n",
       "      <td>117.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>30.50</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.00</td>\n",
       "      <td>140.25</td>\n",
       "      <td>80.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>127.25</td>\n",
       "      <td>36.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>41.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>122.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>846.00</td>\n",
       "      <td>67.10</td>\n",
       "      <td>2.42</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         preg    plas    pres    skin    insu    mass    pedi     age\n",
       "count  768.00  768.00  768.00  768.00  768.00  768.00  768.00  768.00\n",
       "mean     3.85  120.89   69.11   20.54   79.80   31.99    0.47   33.24\n",
       "std      3.37   31.97   19.36   15.95  115.24    7.88    0.33   11.76\n",
       "min      0.00    0.00    0.00    0.00    0.00    0.00    0.08   21.00\n",
       "25%      1.00   99.00   62.00    0.00    0.00   27.30    0.24   24.00\n",
       "50%      3.00  117.00   72.00   23.00   30.50   32.00    0.37   29.00\n",
       "75%      6.00  140.25   80.00   32.00  127.25   36.60    0.63   41.00\n",
       "max     17.00  199.00  122.00   99.00  846.00   67.10    2.42   81.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetes_data = oml.datasets.get_dataset(37)\n",
    "X_diabetes, y_diabetes, attributes_diabetes = diabetes_data.get_data(\n",
    "    target=diabetes_data.default_target_attribute,\n",
    "    return_attribute_names=True)\n",
    "\n",
    "diabetes_df = pd.DataFrame(X_diabetes, columns=attributes_diabetes)\n",
    "display(diabetes_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Favorite_Points</th>\n",
       "      <th>Underdog_Points</th>\n",
       "      <th>Pointspread</th>\n",
       "      <th>Favorite_Name</th>\n",
       "      <th>Underdog_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>672.00</td>\n",
       "      <td>672.00</td>\n",
       "      <td>672.00</td>\n",
       "      <td>672.00</td>\n",
       "      <td>672.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.95</td>\n",
       "      <td>16.86</td>\n",
       "      <td>5.31</td>\n",
       "      <td>13.48</td>\n",
       "      <td>13.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.97</td>\n",
       "      <td>9.27</td>\n",
       "      <td>3.31</td>\n",
       "      <td>8.23</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.00</td>\n",
       "      <td>16.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>21.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>19.50</td>\n",
       "      <td>27.00</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Favorite_Points  Underdog_Points  Pointspread  Favorite_Name  \\\n",
       "count           672.00           672.00       672.00         672.00   \n",
       "mean             22.95            16.86         5.31          13.48   \n",
       "std               9.97             9.27         3.31           8.23   \n",
       "min               0.00             0.00         0.00           0.00   \n",
       "25%              16.00            10.00         3.00           6.00   \n",
       "50%              23.00            16.50         5.00          14.00   \n",
       "75%              29.00            23.00         7.00          20.00   \n",
       "max              61.00            47.00        19.50          27.00   \n",
       "\n",
       "       Underdog_name  \n",
       "count         672.00  \n",
       "mean           13.52  \n",
       "std             7.93  \n",
       "min             0.00  \n",
       "25%             7.00  \n",
       "50%            13.00  \n",
       "75%            21.00  \n",
       "max            27.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "profb_data = oml.datasets.get_dataset(470)\n",
    "X_raw_profb, y_profb, attributes_profb = profb_data.get_data(\n",
    "    target=profb_data.default_target_attribute,\n",
    "    return_attribute_names=True)\n",
    "\n",
    "profb_df = pd.DataFrame(X_raw_profb, columns=attributes_profb)\n",
    "profb_df = profb_df[['Favorite_Points','Underdog_Points',\n",
    "                    'Pointspread','Favorite_Name','Underdog_name']]\n",
    "display(profb_df.describe())\n",
    "profb_df = pd.get_dummies(profb_df, columns=['Favorite_Name', 'Underdog_name'])\n",
    "X_profb = profb_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength:</th>\n",
       "      <th>fWidth:</th>\n",
       "      <th>fSize:</th>\n",
       "      <th>fConc:</th>\n",
       "      <th>...</th>\n",
       "      <th>fM3Long:</th>\n",
       "      <th>fM3Trans:</th>\n",
       "      <th>fAlpha:</th>\n",
       "      <th>fDist:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19020.00</td>\n",
       "      <td>19020.00</td>\n",
       "      <td>19020.00</td>\n",
       "      <td>19020.00</td>\n",
       "      <td>...</td>\n",
       "      <td>19020.00</td>\n",
       "      <td>19020.00</td>\n",
       "      <td>19020.00</td>\n",
       "      <td>19020.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.25</td>\n",
       "      <td>22.18</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>10.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>27.65</td>\n",
       "      <td>193.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.36</td>\n",
       "      <td>18.35</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>51.00</td>\n",
       "      <td>20.83</td>\n",
       "      <td>26.10</td>\n",
       "      <td>74.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-331.78</td>\n",
       "      <td>-205.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.34</td>\n",
       "      <td>11.86</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.84</td>\n",
       "      <td>-10.85</td>\n",
       "      <td>5.55</td>\n",
       "      <td>142.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.15</td>\n",
       "      <td>17.14</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>15.31</td>\n",
       "      <td>0.67</td>\n",
       "      <td>17.68</td>\n",
       "      <td>191.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.12</td>\n",
       "      <td>24.74</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>35.84</td>\n",
       "      <td>10.95</td>\n",
       "      <td>45.88</td>\n",
       "      <td>240.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>334.18</td>\n",
       "      <td>256.38</td>\n",
       "      <td>5.32</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>238.32</td>\n",
       "      <td>179.85</td>\n",
       "      <td>90.00</td>\n",
       "      <td>495.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fLength:   fWidth:    fSize:    fConc:    ...     fM3Long:  fM3Trans:  \\\n",
       "count  19020.00  19020.00  19020.00  19020.00    ...     19020.00   19020.00   \n",
       "mean      53.25     22.18      2.83      0.38    ...        10.55       0.25   \n",
       "std       42.36     18.35      0.47      0.18    ...        51.00      20.83   \n",
       "min        4.28      0.00      1.94      0.01    ...      -331.78    -205.89   \n",
       "25%       24.34     11.86      2.48      0.24    ...       -12.84     -10.85   \n",
       "50%       37.15     17.14      2.74      0.35    ...        15.31       0.67   \n",
       "75%       70.12     24.74      3.10      0.50    ...        35.84      10.95   \n",
       "max      334.18    256.38      5.32      0.89    ...       238.32     179.85   \n",
       "\n",
       "        fAlpha:    fDist:  \n",
       "count  19020.00  19020.00  \n",
       "mean      27.65    193.82  \n",
       "std       26.10     74.73  \n",
       "min        0.00      1.28  \n",
       "25%        5.55    142.49  \n",
       "50%       17.68    191.85  \n",
       "75%       45.88    240.56  \n",
       "max       90.00    495.56  \n",
       "\n",
       "[8 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1120\n",
    "telescope_data = oml.datasets.get_dataset(1120)\n",
    "X_telescope, y_telescope, attributes_telescope = telescope_data.get_data(\n",
    "    target=telescope_data.default_target_attribute,\n",
    "    return_attribute_names=True)\n",
    "\n",
    "telescope_df = pd.DataFrame(X_telescope, columns=attributes_telescope)\n",
    "display(telescope_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>748.00</td>\n",
       "      <td>748.00</td>\n",
       "      <td>748.00</td>\n",
       "      <td>748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.51</td>\n",
       "      <td>5.51</td>\n",
       "      <td>1378.68</td>\n",
       "      <td>34.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.10</td>\n",
       "      <td>5.84</td>\n",
       "      <td>1459.83</td>\n",
       "      <td>24.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.75</td>\n",
       "      <td>2.00</td>\n",
       "      <td>500.00</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>1750.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>12500.00</td>\n",
       "      <td>98.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           V1      V2        V3      V4\n",
       "count  748.00  748.00    748.00  748.00\n",
       "mean     9.51    5.51   1378.68   34.28\n",
       "std      8.10    5.84   1459.83   24.38\n",
       "min      0.00    1.00    250.00    2.00\n",
       "25%      2.75    2.00    500.00   16.00\n",
       "50%      7.00    4.00   1000.00   28.00\n",
       "75%     14.00    7.00   1750.00   50.00\n",
       "max     74.00   50.00  12500.00   98.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1464\n",
    "blood_data = oml.datasets.get_dataset(1464)\n",
    "X_blood, y_blood, attributes_blood = blood_data.get_data(\n",
    "    target=blood_data.default_target_attribute,\n",
    "    return_attribute_names=True)\n",
    "\n",
    "blood_df = pd.DataFrame(X_blood, columns=attributes_blood)\n",
    "display(blood_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>...</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14980.00</td>\n",
       "      <td>14980.00</td>\n",
       "      <td>14980.00</td>\n",
       "      <td>14980.00</td>\n",
       "      <td>...</td>\n",
       "      <td>14980.00</td>\n",
       "      <td>14980.00</td>\n",
       "      <td>14980.00</td>\n",
       "      <td>14980.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4321.90</td>\n",
       "      <td>4009.78</td>\n",
       "      <td>4264.03</td>\n",
       "      <td>4164.96</td>\n",
       "      <td>...</td>\n",
       "      <td>4202.45</td>\n",
       "      <td>4279.24</td>\n",
       "      <td>4615.21</td>\n",
       "      <td>4416.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2492.02</td>\n",
       "      <td>45.94</td>\n",
       "      <td>44.43</td>\n",
       "      <td>5216.36</td>\n",
       "      <td>...</td>\n",
       "      <td>37.79</td>\n",
       "      <td>41.54</td>\n",
       "      <td>1208.36</td>\n",
       "      <td>5890.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1030.77</td>\n",
       "      <td>2830.77</td>\n",
       "      <td>1040.00</td>\n",
       "      <td>2453.33</td>\n",
       "      <td>...</td>\n",
       "      <td>3273.33</td>\n",
       "      <td>2257.95</td>\n",
       "      <td>86.67</td>\n",
       "      <td>1366.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4280.51</td>\n",
       "      <td>3990.77</td>\n",
       "      <td>4250.26</td>\n",
       "      <td>4108.21</td>\n",
       "      <td>...</td>\n",
       "      <td>4190.26</td>\n",
       "      <td>4267.69</td>\n",
       "      <td>4590.77</td>\n",
       "      <td>4342.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4294.36</td>\n",
       "      <td>4005.64</td>\n",
       "      <td>4262.56</td>\n",
       "      <td>4120.51</td>\n",
       "      <td>...</td>\n",
       "      <td>4200.51</td>\n",
       "      <td>4276.92</td>\n",
       "      <td>4603.08</td>\n",
       "      <td>4354.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4311.79</td>\n",
       "      <td>4023.08</td>\n",
       "      <td>4270.77</td>\n",
       "      <td>4132.31</td>\n",
       "      <td>...</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4287.18</td>\n",
       "      <td>4617.44</td>\n",
       "      <td>4372.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>309231.00</td>\n",
       "      <td>7804.62</td>\n",
       "      <td>6880.51</td>\n",
       "      <td>642564.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6823.08</td>\n",
       "      <td>7002.56</td>\n",
       "      <td>152308.00</td>\n",
       "      <td>715897.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3         V4    ...           V11  \\\n",
       "count   14980.00  14980.00  14980.00   14980.00    ...      14980.00   \n",
       "mean     4321.90   4009.78   4264.03    4164.96    ...       4202.45   \n",
       "std      2492.02     45.94     44.43    5216.36    ...         37.79   \n",
       "min      1030.77   2830.77   1040.00    2453.33    ...       3273.33   \n",
       "25%      4280.51   3990.77   4250.26    4108.21    ...       4190.26   \n",
       "50%      4294.36   4005.64   4262.56    4120.51    ...       4200.51   \n",
       "75%      4311.79   4023.08   4270.77    4132.31    ...       4211.28   \n",
       "max    309231.00   7804.62   6880.51  642564.00    ...       6823.08   \n",
       "\n",
       "            V12        V13        V14  \n",
       "count  14980.00   14980.00   14980.00  \n",
       "mean    4279.24    4615.21    4416.44  \n",
       "std       41.54    1208.36    5890.98  \n",
       "min     2257.95      86.67    1366.15  \n",
       "25%     4267.69    4590.77    4342.05  \n",
       "50%     4276.92    4603.08    4354.87  \n",
       "75%     4287.18    4617.44    4372.82  \n",
       "max     7002.56  152308.00  715897.00  \n",
       "\n",
       "[8 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1471\n",
    "eeg_data = oml.datasets.get_dataset(1471)\n",
    "X_eeg, y_eeg, attributes_eeg = eeg_data.get_data(\n",
    "    target=eeg_data.default_target_attribute,\n",
    "    return_attribute_names=True)\n",
    "\n",
    "eeg_df = pd.DataFrame(X_eeg, columns=attributes_eeg)\n",
    "display(eeg_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##feature engineering to:\n",
    "## -> diabetes_data (scaling)\n",
    "## -> profb_data (select important columns, encode categorical values)\n",
    "## -> telescope_data (scaling)\n",
    "## -> blood_data (scaling)\n",
    "## -> eeg_data (scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>profb</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>telescope</th>\n",
       "      <th>blood</th>\n",
       "      <th>eeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  clf  profb  diabetes  telescope  blood   eeg\n",
       "0                 kNN   0.60      0.78       0.88   0.51  0.47\n",
       "1  LogisticRegression   0.77      0.83       0.84   0.95  0.47\n",
       "2                 SVM   0.66      0.83       0.87   0.78  0.42"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run kNN, Logistic Regression and SVM on diabetes dataset using pipelines\n",
    "clf_scores = []\n",
    "\n",
    "#run kNN over all datasets\n",
    "knn_scores = {'clf': 'kNN'}\n",
    "knn_pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"knn\", KNeighborsClassifier())])\n",
    "\n",
    "scores = cross_val_score(knn_pipe, X_diabetes, y_diabetes, cv=10, scoring='roc_auc')\n",
    "knn_scores['diabetes'] = scores.mean()\n",
    "scores = cross_val_score(knn_pipe, X_telescope, y_telescope, cv=10, scoring='roc_auc')\n",
    "knn_scores['telescope'] = scores.mean()\n",
    "scores = cross_val_score(knn_pipe, X_blood, y_blood, cv=10, scoring='roc_auc')\n",
    "knn_scores['blood'] = scores.mean()\n",
    "scores = cross_val_score(knn_pipe, X_eeg, y_eeg, cv=10, scoring='roc_auc')\n",
    "knn_scores['eeg'] = scores.mean()\n",
    "\n",
    "scores = cross_val_score(KNeighborsClassifier(), X_profb, y_profb, cv=10, scoring='roc_auc')\n",
    "knn_scores['profb'] = scores.mean()\n",
    "clf_scores.append(knn_scores)\n",
    "\n",
    "\n",
    "#run Logistic Regression over all datasets\n",
    "logistic_scores = {'clf': 'LogisticRegression'}\n",
    "logistic_pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"logistic\", LogisticRegression())])\n",
    "\n",
    "scores = cross_val_score(logistic_pipe, X_diabetes, y_diabetes, cv=10, scoring='roc_auc')\n",
    "logistic_scores['diabetes'] = scores.mean()\n",
    "scores = cross_val_score(logistic_pipe, X_telescope, y_telescope, cv=10, scoring='roc_auc')\n",
    "logistic_scores['telescope'] = scores.mean()\n",
    "scores = cross_val_score(logistic_pipe, X_blood, y_blood, cv=10, scoring='roc_auc')\n",
    "logistic_scores['blood'] = scores.mean()\n",
    "scores = cross_val_score(logistic_pipe, X_eeg, y_eeg, cv=10, scoring='roc_auc')\n",
    "logistic_scores['eeg'] = scores.mean()\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), X_profb, y_profb, cv=10, scoring='roc_auc')\n",
    "logistic_scores['profb'] = scores.mean()\n",
    "clf_scores.append(logistic_scores)\n",
    "\n",
    "\n",
    "\n",
    "#run SVM over all datasets\n",
    "svm_scores = {'clf': 'SVM'}\n",
    "svm_pipe = Pipeline([(\"scaler\", MinMaxScaler()), (\"svm\", SVC())])\n",
    "\n",
    "scores = cross_val_score(svm_pipe, X_diabetes, y_diabetes, cv=10, scoring='roc_auc')\n",
    "svm_scores['diabetes'] = scores.mean()\n",
    "scores = cross_val_score(svm_pipe, X_telescope, y_telescope, cv=10, scoring='roc_auc')\n",
    "svm_scores['telescope'] = scores.mean()\n",
    "scores = cross_val_score(svm_pipe, X_blood, y_blood, cv=10, scoring='roc_auc')\n",
    "svm_scores['blood'] = scores.mean()\n",
    "scores = cross_val_score(svm_pipe, X_eeg, y_eeg, cv=10, scoring='roc_auc')\n",
    "svm_scores['eeg'] = scores.mean()\n",
    "\n",
    "scores = cross_val_score(SVC(), X_profb, y_profb, cv=10, scoring='roc_auc')\n",
    "svm_scores['profb'] = scores.mean()\n",
    "clf_scores.append(svm_scores)\n",
    "\n",
    "scores_df = pd.DataFrame(clf_scores)\n",
    "scores_df = scores_df[['clf', 'profb', 'diabetes', 'telescope', 'blood', 'eeg']]\n",
    "display(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate all classifiers (with default parameter settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following classifiers (with default parametesr settings) were evaluated over 5 datasets:\n",
    "* kNN \n",
    "* Logistic Regression\n",
    "* SVM\n",
    "\n",
    "From the table we get that Logistic Regression performs better for 4 datasets, kNN for 2 and SVM 1. Therefore we are inclined to think that Logistic Regression has the best performance, also it does not take as much time to train as SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tune_parameters(clf, params, X, y):\n",
    "    [X_train, X_test, y_train, y_test] = train_test_split(X,y,\n",
    "                                                     test_size=0.2,\n",
    "                                                    random_state=0,\n",
    "                                                     stratify=y)\n",
    "    grid_search = GridSearchCV(clf,\n",
    "                           params,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_params_\n",
    "\n",
    "def tune_svm_parameters(clf, params, X, y, n_iter_search):\n",
    "    [X_train, X_test, y_train, y_test] = train_test_split(X,y,\n",
    "                                                     test_size=0.2,\n",
    "                                                    random_state=0,\n",
    "                                                     stratify=y)\n",
    "    best_score = 0.0\n",
    "    best_params = None\n",
    "    for param_grid in params:\n",
    "        random_search = RandomizedSearchCV(clf,\n",
    "                                       param_distributions=param_grid,\n",
    "                                       n_iter=n_iter_search,\n",
    "                                       scoring='roc_auc',\n",
    "                                       cv=5)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    if random_search.best_score_ > best_score:\n",
    "        best_params = random_search.best_params_\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 13}\n",
      "{'n_neighbors': 15}\n",
      "{'n_neighbors': 7}\n",
      "{'n_neighbors': 5}\n",
      "{'n_neighbors': 5}\n",
      "{'diabetes': 0.80973646723646731, 'blood': 0.53439972480220166, 'telescope': 0.900310571597149, 'profb': 0.61405956801213712, 'clf': 'kNN', 'eeg': 0.47353510267537324}\n"
     ]
    }
   ],
   "source": [
    "##optimizing main hyperparameters for knn\n",
    "## weight -> (uniform, distance)\n",
    "## n_neighbors -> (3, 5, 7, 9, 11, 13, 15)\n",
    "\n",
    "clf_scores = []\n",
    "\n",
    "knn_params = [{'n_neighbors': [3,5,7,9,11,13,15]}]\n",
    "\n",
    "#run kNN over all datasets\n",
    "knn_scores = {'clf': 'kNN'}\n",
    "\n",
    "#### performance for diabetes ####\n",
    "knn_best_params = tune_parameters(KNeighborsClassifier(),\n",
    "                                 knn_params,\n",
    "                                 X_diabetes,\n",
    "                                 y_diabetes)\n",
    "\n",
    "knn_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"knn\", KNeighborsClassifier(**knn_best_params))])\n",
    "\n",
    "scores = cross_val_score(knn_pipe, X_diabetes, y_diabetes, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "knn_scores['diabetes'] = scores.mean()\n",
    "print(knn_best_params)\n",
    "\n",
    "#### performance for telescope ####\n",
    "knn_best_params = tune_parameters(KNeighborsClassifier(),\n",
    "                                 knn_params,\n",
    "                                 X_telescope,\n",
    "                                 y_telescope)\n",
    "\n",
    "knn_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"knn\", KNeighborsClassifier(**knn_best_params))])\n",
    "\n",
    "scores = cross_val_score(knn_pipe, X_telescope, y_telescope, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "knn_scores['telescope'] = scores.mean()\n",
    "print(knn_best_params)\n",
    "\n",
    "#### performance for blood ####\n",
    "knn_best_params = tune_parameters(KNeighborsClassifier(),\n",
    "                                 knn_params,\n",
    "                                 X_blood,\n",
    "                                 y_blood)\n",
    "\n",
    "knn_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"knn\", KNeighborsClassifier(**knn_best_params))])\n",
    "\n",
    "scores = cross_val_score(knn_pipe, X_blood, y_blood, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "knn_scores['blood'] = scores.mean()\n",
    "print(knn_best_params)\n",
    "\n",
    "#### performance for eeg ####\n",
    "knn_best_params = tune_parameters(KNeighborsClassifier(),\n",
    "                                 knn_params,\n",
    "                                 X_eeg,\n",
    "                                 y_eeg)\n",
    "\n",
    "knn_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"knn\", KNeighborsClassifier(**knn_best_params))])\n",
    "\n",
    "scores = cross_val_score(knn_pipe, X_eeg, y_eeg, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "knn_scores['eeg'] = scores.mean()\n",
    "print(knn_best_params)\n",
    "\n",
    "#### performance for profb ####\n",
    "scores= cross_val_score(GridSearchCV(KNeighborsClassifier(),\n",
    "                                     knn_params,\n",
    "                                     scoring='roc_auc',\n",
    "                                     cv=5),\n",
    "                        X_profb, y_profb,\n",
    "                        cv=10, scoring='roc_auc')\n",
    "knn_scores['profb'] = scores.mean()\n",
    "print(knn_best_params)\n",
    "\n",
    "print(knn_scores)\n",
    "\n",
    "clf_scores.append(knn_scores)\n",
    "\n",
    "\n",
    "## -> diabetes_data (scaling)\n",
    "## -> profb_data (select important columns, encode categorical values)\n",
    "## -> telescope_data (scaling)\n",
    "## -> blood_data (scaling)\n",
    "## -> eeg_data (scaling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.01, 'C': 0.1, 'kernel': 'rbf'}\n",
      "{'gamma': 0.001, 'C': 1, 'kernel': 'rbf'}\n",
      "{'gamma': 0.001, 'C': 10, 'kernel': 'rbf'}\n",
      "{'gamma': 0.001, 'C': 100, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "##optimizing main hyperparameters for svm\n",
    "\n",
    "svm_params = [\n",
    "    {'kernel': ['poly'],\n",
    "     'C': [0.001, 0.01, 0.1, 1, 10, 100, 100],\n",
    "     'degree': np.arange(3,10).tolist(),\n",
    "     'coef0': [1.0/4, 1.0/2, 1.0, 2, 4, 8, 16]},\n",
    "    {'kernel': ['rbf'], \n",
    "     'C': [0.001, 0.01, 0.1, 1, 10, 100, 100], \n",
    "     'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "]\n",
    "\n",
    "n_iter_search = 5\n",
    "\n",
    "#run kNN over all datasets\n",
    "svm_scores = {'clf': 'SVM'}\n",
    "\n",
    "#### performance for diabetes ####\n",
    "svm_best_params = tune_svm_parameters(SVC(),\n",
    "                                 svm_params,\n",
    "                                 X_diabetes,\n",
    "                                 y_diabetes,\n",
    "                                     n_iter_search)\n",
    "\n",
    "svm_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"svm\", SVC(**svm_best_params))])\n",
    "\n",
    "scores = cross_val_score(svm_pipe, X_diabetes, y_diabetes, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "svm_scores['diabetes'] = scores.mean()\n",
    "print(svm_best_params)\n",
    "\n",
    "#### performance for telescope ####\n",
    "svm_best_params = tune_svm_parameters(SVC(),\n",
    "                                 svm_params,\n",
    "                                 X_telescope,\n",
    "                                 y_telescope,\n",
    "                                     n_iter_search)\n",
    "\n",
    "svm_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"svm\", SVC(**svm_best_params))])\n",
    "\n",
    "scores = cross_val_score(svm_pipe, X_telescope, y_telescope, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "svm_scores['telescope'] = scores.mean()\n",
    "print(svm_best_params)\n",
    "\n",
    "#### performance for blood ####\n",
    "svm_best_params = tune_svm_parameters(SVC(),\n",
    "                                 svm_params,\n",
    "                                 X_blood,\n",
    "                                 y_blood,\n",
    "                                     n_iter_search)\n",
    "\n",
    "svm_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"svm\", SVC(**svm_best_params))])\n",
    "\n",
    "scores = cross_val_score(svm_pipe, X_blood, y_blood, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "svm_scores['blood'] = scores.mean()\n",
    "print(svm_best_params)\n",
    "\n",
    "#### performance for eeg ####\n",
    "svm_best_params = tune_svm_parameters(SVC(),\n",
    "                                 svm_params,\n",
    "                                 X_eeg,\n",
    "                                 y_eeg,\n",
    "                                     n_iter_search)\n",
    "\n",
    "svm_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"svm\", SVC(**svm_best_params))])\n",
    "\n",
    "scores = cross_val_score(svm_pipe, X_eeg, y_eeg, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "svm_scores['eeg'] = scores.mean()\n",
    "print(svm_best_params)\n",
    "\n",
    "#### performance for profb ####\n",
    "# Random search over polynomial kernel parameters\n",
    "poly_scores = cross_val_score(RandomizedSearchCV(SVC(),\n",
    "                                     svm_params[0],\n",
    "                                     n_iter = n_iter_search,\n",
    "                                     scoring='roc_auc',\n",
    "                                     cv=5),\n",
    "                        X_profb, y_profb,\n",
    "                        cv=10, scoring='roc_auc')\n",
    "\n",
    "# Random search over rbf kernel parameters\n",
    "rbf_scores = cross_val_score(RandomizedSearchCV(SVC(),\n",
    "                                     svm_params[1],\n",
    "                                     n_iter = n_iter_search,\n",
    "                                     scoring='roc_auc',\n",
    "                                     cv=5),\n",
    "                        X_profb, y_profb,\n",
    "                        cv=10, scoring='roc_auc')\n",
    "\n",
    "if poly_scores.mean() > rbf_scores.mean():\n",
    "    svm_scores['profb'] = poly_scores.mean()\n",
    "else:\n",
    "    svm_scores['profb'] = rbf_scores.mean()\n",
    "\n",
    "clf_scores.append(svm_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l2', 'C': 1000}\n",
      "{'penalty': 'l2', 'C': 100}\n",
      "{'penalty': 'l1', 'C': 10}\n",
      "{'penalty': 'l2', 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "##optimizing main hyperparameters for logistic regression\n",
    "\n",
    "logistic_params = {'C': [0.0001,0.001,0.01,0.1,1,10,100, 1000],\n",
    "                   'penalty': ['l1', 'l2']}\n",
    "\n",
    "#run kNN over all datasets\n",
    "logistic_scores = {'clf': 'LogisticRegression'}\n",
    "\n",
    "#### performance for diabetes ####\n",
    "logistic_best_params = tune_parameters(LogisticRegression(),\n",
    "                                 logistic_params,\n",
    "                                 X_diabetes,\n",
    "                                 y_diabetes)\n",
    "\n",
    "logistic_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"logistic\", LogisticRegression(**logistic_best_params))])\n",
    "\n",
    "scores = cross_val_score(logistic_pipe, X_diabetes, y_diabetes, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "logistic_scores['diabetes'] = scores.mean()\n",
    "print(logistic_best_params)\n",
    "\n",
    "#### performance for telescope ####\n",
    "logistic_best_params = tune_parameters(LogisticRegression(),\n",
    "                                 logistic_params,\n",
    "                                 X_telescope,\n",
    "                                 y_telescope)\n",
    "\n",
    "logistic_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"logistic\", LogisticRegression(**logistic_best_params))])\n",
    "\n",
    "scores = cross_val_score(logistic_pipe, X_telescope, y_telescope, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "logistic_scores['telescope'] = scores.mean()\n",
    "print(logistic_best_params)\n",
    "\n",
    "#### performance for blood ####\n",
    "logistic_best_params = tune_parameters(LogisticRegression(),\n",
    "                                 logistic_params,\n",
    "                                 X_blood,\n",
    "                                 y_blood)\n",
    "\n",
    "logistic_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"logistic\", LogisticRegression(**logistic_best_params))])\n",
    "\n",
    "scores = cross_val_score(logistic_pipe, X_blood, y_blood, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "logistic_scores['blood'] = scores.mean()\n",
    "print(logistic_best_params)\n",
    "\n",
    "#### performance for eeg ####\n",
    "logistic_best_params = tune_parameters(LogisticRegression(),\n",
    "                                 logistic_params,\n",
    "                                 X_eeg,\n",
    "                                 y_eeg)\n",
    "\n",
    "logistic_pipe = Pipeline([(\"scaler\", MinMaxScaler()),\n",
    "                     (\"logistic\", LogisticRegression(**logistic_best_params))])\n",
    "\n",
    "scores = cross_val_score(logistic_pipe, X_eeg, y_eeg, \n",
    "                         cv=10, scoring='roc_auc')\n",
    "logistic_scores['eeg'] = scores.mean()\n",
    "print(logistic_best_params)\n",
    "\n",
    "#### performance for profb ####\n",
    "scores= cross_val_score(GridSearchCV(LogisticRegression(),\n",
    "                                     logistic_params,\n",
    "                                     scoring='roc_auc',\n",
    "                                     cv=5),\n",
    "                        X_profb, y_profb,\n",
    "                        cv=10, scoring='roc_auc')\n",
    "logistic_scores['profb'] = scores.mean()\n",
    "\n",
    "clf_scores.append(logistic_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark with optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf</th>\n",
       "      <th>profb</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>telescope</th>\n",
       "      <th>blood</th>\n",
       "      <th>eeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  clf  profb  diabetes  telescope  blood   eeg\n",
       "0                 kNN   0.61      0.81       0.90   0.53  0.47\n",
       "1                 SVM   0.72      0.82       0.81   0.81  0.42\n",
       "2  LogisticRegression   0.76      0.83       0.84   0.95  0.46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(clf_scores)\n",
    "scores_df = scores_df[['clf', 'profb', 'diabetes', 'telescope', 'blood', 'eeg']]\n",
    "display(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the table above we get that kNN performs better for 2 datasets and Logistic regression for the other 3. We are inclined to think that Logistic regression has a better performance than the other classifiers.\n",
    "The hyperparameter optimization made kNN perform better and SVM perform worse relative to the other classifiers, the ranking was not affected. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
